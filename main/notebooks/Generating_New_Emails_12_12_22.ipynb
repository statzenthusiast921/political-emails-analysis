{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecfe527-da4f-4de2-86c4-76891ea83fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 17:00:04.877053: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-13 17:00:04.877943: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-13 17:00:04.877953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "#!pip install keras.preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import string\n",
    "from tensorflow import keras\n",
    "#!pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#!pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df993e1-f93c-49ad-8eeb-3f3fa0924899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 20)\n",
      "(19000, 20)\n",
      "(19000, 20)\n",
      "(17148, 20)\n"
     ]
    }
   ],
   "source": [
    "#Read in the data\n",
    "import pandas as pd\n",
    "\n",
    "df1=pd.read_csv(\"https://raw.githubusercontent.com/statzenthusiast921/political-emails-analysis/main/main/data/clean_emails_df1.csv\")\n",
    "df2=pd.read_csv(\"https://raw.githubusercontent.com/statzenthusiast921/political-emails-analysis/main/main/data/clean_emails_df2.csv\")\n",
    "df3=pd.read_csv(\"https://raw.githubusercontent.com/statzenthusiast921/political-emails-analysis/main/main/data/clean_emails_df3.csv\")\n",
    "df4=pd.read_csv(\"https://raw.githubusercontent.com/statzenthusiast921/political-emails-analysis/main/main/data/clean_emails_df4.csv\")\n",
    "\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142e22f1-12a5-42d8-8dc4-eca2bf14aa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>party</th>\n",
       "      <th>country</th>\n",
       "      <th>locality</th>\n",
       "      <th>office</th>\n",
       "      <th>time</th>\n",
       "      <th>AM_PM</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Hour_Mil</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>month_num</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TAKE ACTION for Freedom: #CloseTheCamps</td>\n",
       "      <td>July 3, 2019</td>\n",
       "      <td>Dear friend, We have all seen the images and r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:31 PM</td>\n",
       "      <td>PM</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>July</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>dear friend seen images read stories migrants ...</td>\n",
       "      <td>{'neg': 0.207, 'neu': 0.674, 'pos': 0.12, 'com...</td>\n",
       "      <td>-0.9807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trauma-informed schools</td>\n",
       "      <td>July 3, 2019</td>\n",
       "      <td>Team,Access to education is fundamental to a c...</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>11:32 PM</td>\n",
       "      <td>PM</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>July</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>team access education fundamental child succes...</td>\n",
       "      <td>{'neg': 0.143, 'neu': 0.658, 'pos': 0.199, 'co...</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Juárez</td>\n",
       "      <td>July 3, 2019</td>\n",
       "      <td>Beto for America John, The Trump administrati...</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>United States</td>\n",
       "      <td>Texas</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>11:32 PM</td>\n",
       "      <td>PM</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>July</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>beto america john trump administration created...</td>\n",
       "      <td>{'neg': 0.069, 'neu': 0.684, 'pos': 0.247, 'co...</td>\n",
       "      <td>0.9578</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andy's new veterans jobs plan</td>\n",
       "      <td>July 4, 2019</td>\n",
       "      <td>John,Tomorrow is the Fourth of July, a day for...</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>United States</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>State Governor</td>\n",
       "      <td>12:15 AM</td>\n",
       "      <td>AM</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>July</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>john tomorrow fourth july day us come together...</td>\n",
       "      <td>{'neg': 0.023, 'neu': 0.636, 'pos': 0.341, 'co...</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>say NO to Trump's military parade [signature n...</td>\n",
       "      <td>July 4, 2019</td>\n",
       "      <td>Tomorrow is the Fourth of July, and Donald Tru...</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>President of the United States</td>\n",
       "      <td>12:19 AM</td>\n",
       "      <td>AM</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>July</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>tomorrow fourth july donald trump using day th...</td>\n",
       "      <td>{'neg': 0.078, 'neu': 0.684, 'pos': 0.238, 'co...</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject          date  \\\n",
       "1            TAKE ACTION for Freedom: #CloseTheCamps  July 3, 2019   \n",
       "2                            trauma-informed schools  July 3, 2019   \n",
       "3                                            Juárez  July 3, 2019   \n",
       "4                      Andy's new veterans jobs plan  July 4, 2019   \n",
       "5  say NO to Trump's military parade [signature n...  July 4, 2019   \n",
       "\n",
       "                                                body       party  \\\n",
       "1  Dear friend, We have all seen the images and r...         NaN   \n",
       "2  Team,Access to education is fundamental to a c...  Democratic   \n",
       "3   Beto for America John, The Trump administrati...  Democratic   \n",
       "4  John,Tomorrow is the Fourth of July, a day for...  Democratic   \n",
       "5  Tomorrow is the Fourth of July, and Donald Tru...  Democratic   \n",
       "\n",
       "         country  locality                          office      time AM_PM  \\\n",
       "1  United States       NaN                             NaN  11:31 PM    PM   \n",
       "2  United States      Ohio  President of the United States  11:32 PM    PM   \n",
       "3  United States     Texas  President of the United States  11:32 PM    PM   \n",
       "4  United States  Kentucky                  State Governor  12:15 AM    AM   \n",
       "5  United States       NaN  President of the United States  12:19 AM    AM   \n",
       "\n",
       "   Hour  Hour_Mil month  day  year  month_num  \\\n",
       "1    11        23  July    3  2019          7   \n",
       "2    11        23  July    3  2019          7   \n",
       "3    11        23  July    3  2019          7   \n",
       "4    12         0  July    4  2019          7   \n",
       "5    12         0  July    4  2019          7   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "1  dear friend seen images read stories migrants ...   \n",
       "2  team access education fundamental child succes...   \n",
       "3  beto america john trump administration created...   \n",
       "4  john tomorrow fourth july day us come together...   \n",
       "5  tomorrow fourth july donald trump using day th...   \n",
       "\n",
       "                                           sentiment  compound  comp_score  \n",
       "1  {'neg': 0.207, 'neu': 0.674, 'pos': 0.12, 'com...   -0.9807           0  \n",
       "2  {'neg': 0.143, 'neu': 0.658, 'pos': 0.199, 'co...    0.7269           1  \n",
       "3  {'neg': 0.069, 'neu': 0.684, 'pos': 0.247, 'co...    0.9578           1  \n",
       "4  {'neg': 0.023, 'neu': 0.636, 'pos': 0.341, 'co...    0.9867           1  \n",
       "5  {'neg': 0.078, 'neu': 0.684, 'pos': 0.238, 'co...    0.8316           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stack 4 dataframes together\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True, axis=0)\n",
    "#Delete first row and column\n",
    "df = df[1:]\n",
    "df = df.iloc[: , 1:]\n",
    "\n",
    "#Drop NAs from cleaned_body and body\n",
    "df = df[df['cleaned_body'].notna()]\n",
    "#Preview dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734d77fd-9c14-41fd-bca9-4d7629da8ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73694, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['year']>1970]\n",
    "df['locality'] = np.where(df['locality']==\"MIchigan\",\"Michigan\",df['locality'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72834da-4c9e-4020-ab91-346467da7186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "# stop_words.extend([\"uh\",\"oh\",\"okay\",\"im\",\"dont\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1d689c9-4805-4f2c-8c67-cf89573337d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body'] = df['body'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51cfb968-eca5-427f-b1ee-2fe60bc1d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brackets_contents(text):\n",
    "    pattern = r\"\\[.*?\\]\"\n",
    "    return re.sub(pattern, \" \", text)\n",
    "\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # define the pattern to keep\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pat, ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f5ecf3f-2f47-4f27-ae6d-d1d7338292f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df['body'] = df['body'].replace('\\n','',regex=True)\n",
    "df['body'] = df['body'].replace('\\r','',regex=True)\n",
    "df.loc[:,'body'] = df['body'].apply(func = remove_brackets_contents)\n",
    "df.loc[:,'body'] = df['body'].apply(func = remove_special_characters)\n",
    "\n",
    "\n",
    "df['body'] = df['body'].replace('   ',' ',regex=True)\n",
    "df['body'] = df['body'].replace('    ',' ',regex=True)\n",
    "df['body'] = df['body'].replace('     ',' ',regex=True)\n",
    "\n",
    "df['body'] = df['body'].replace(']',' ',regex=True)\n",
    "df['body'] = df['body'].replace('\\xa0',' ',regex=True)\n",
    "df['body'] = df['body'].replace('almostdaily','almost daily',regex=True)\n",
    "\n",
    "\n",
    "#Remove all the text that follows these sentences\n",
    "df['body'] = df['body'].str.replace(\"(If you need to remove yourself from our email).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Email is the most important way).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(This email was sent to).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Thank you for speaking).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(All Rights Reserved).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(mailto:).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Thank you for choosing to fight).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Paid for by).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(We look forward to hearing from you).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(PAID FOR BY).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Thanks for your).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(All rights reserved).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(unsubscribe).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Sincerely).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Facebook).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Twitter).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Please, sign your name).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(CONTRIBUTE).*\",\"\")\n",
    "df['body'] = df['body'].str.replace(\"(Contribute).*\",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ef03a9-ce7c-4e59-8c59-2251243af89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#!pip install contractions\n",
    "import contractions\n",
    "\n",
    "def punct(text):\n",
    "    token=RegexpTokenizer(r'\\w+')#regex\n",
    "    text = token.tokenize(text)\n",
    "    text= \" \".join(text)\n",
    "    return text \n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # define the pattern to keep\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "def remove_digits(text):\n",
    "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmed = contractions.fix(str(text))\n",
    "    return lemmed\n",
    "\n",
    "\n",
    "\n",
    "def remove_weird_words_that_showed_up_in_analysis_(str):\n",
    "    #select english stopwords\n",
    "    #cachedStopWords = set(stopwords.words(\"english\"))\n",
    "    #add custom words\n",
    "    cachedStopWords = set(('height','width','style','saved','payment','information','https',\n",
    "                            'fmailchi','mp','chip','tr','td','style','font','size','px','view'\n",
    "                            'email','browser','zwnj','metered','paywall','articles','vertical',\n",
    "                            'align','top','item','img','src','rss','mc','actblue','com','donate',\n",
    "                            'donation', 'padding','bottom', 'members','pre','unsubscribe','rsquo',\n",
    "                            'headline','lead story','body lead','view email','story body','copy paste',\n",
    "                            'address window','web update','web page','receiving email','page go',\n",
    "                            'go link','paste link','copy fact','receiving newsletter','anymore click',\n",
    "                            'newsletter shown','newsletter clicking','interested anymore','emails view',\n",
    "                            'html emails','software display','display html','please click','web updates',\n",
    "                            'email','emails','interest','interested','newsletter'\n",
    "                           ))\n",
    "    #remove stop words\n",
    "    new_str = ' '.join([word for word in str.split() if word not in cachedStopWords]) \n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76176f2f-a936-45f3-998c-a39236f7575a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    dear friend we have all seen the images and re...\n",
       "2    team access to education is fundamental to a c...\n",
       "3    beto for america john the trump administration...\n",
       "4    john tomorrow is the fourth of july a day for ...\n",
       "5    tomorrow is the fourth of july and donald trum...\n",
       "Name: cleaned_body, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply standardizing functions to body of email column\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#0.) Convert everything to string\n",
    "df['cleaned_body'] = df['body'].astype(str)\n",
    "#1.) Lowercase\n",
    "df.loc[:,'cleaned_body'] = df['cleaned_body'].str.lower()\n",
    "#2.) Remove punctuation\n",
    "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = punct)\n",
    "#3.) Remove non alpha-numeric characters\n",
    "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = remove_special_characters)\n",
    "#4.) Remove digits\n",
    "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = remove_digits)\n",
    "#5.) Lemmatize words\n",
    "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = lemmatize)\n",
    "#6. Remove stop words\n",
    "#df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "#7. Remove weird words that showed up in the analysis\n",
    "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = remove_weird_words_that_showed_up_in_analysis_)\n",
    "\n",
    "#Present results\n",
    "df['cleaned_body'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f5d82cb-96bd-4f2f-ba72-f9003a901d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27737, 19)\n",
      "(6538, 19)\n"
     ]
    }
   ],
   "source": [
    "df_dom = df[df['country']==\"United States\"]\n",
    "\n",
    "DEM_df = df_dom[df_dom['party']==\"Democratic\"].reset_index(drop=True)\n",
    "GOP_df = df_dom[df_dom['party']==\"Republican\"].reset_index(drop=True)\n",
    "\n",
    "print(DEM_df.shape)\n",
    "print(GOP_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171ce0e6-7871-4e7e-a15c-d45b041744cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentiment (GOP): (5638, 19)\n",
      "Negative Sentiment (GOP): (900, 19)\n",
      "\n",
      "\n",
      "Positive Sentiment (DEM): (24722, 19)\n",
      "Negative Sentiment (DEM): (3015, 19)\n"
     ]
    }
   ],
   "source": [
    "GOP_df1 = GOP_df[GOP_df['comp_score']==1]\n",
    "GOP_df0 = GOP_df[GOP_df['comp_score']==0]\n",
    "\n",
    "print('Positive Sentiment (GOP):', GOP_df1.shape)\n",
    "print('Negative Sentiment (GOP):',GOP_df0.shape)\n",
    "\n",
    "print('\\n')\n",
    "DEM_df1 = DEM_df[DEM_df['comp_score']==1]\n",
    "DEM_df0 = DEM_df[DEM_df['comp_score']==0]\n",
    "\n",
    "print('Positive Sentiment (DEM):',DEM_df1.shape)\n",
    "print('Negative Sentiment (DEM):',DEM_df0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd803328-7c82-4358-b41e-e5619ed606cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full datasets\n",
    "DEM = DEM_df.cleaned_body\n",
    "GOP = GOP_df.cleaned_body\n",
    "\n",
    "#GOP datasets broken out by sentiment\n",
    "GOP1 = GOP_df1.cleaned_body\n",
    "GOP0 = GOP_df0.cleaned_body\n",
    "\n",
    "#DEM datasets broken out by sentiment\n",
    "DEM1 = DEM_df1.cleaned_body\n",
    "DEM0 = DEM_df0.cleaned_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f6e2e60-85cc-4f5b-8dc9-ed53fc20e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(doc):\n",
    "    doc = \"\".join(doc)\n",
    "    doc = re.sub(r'[^\\w\\s]', '', doc)\n",
    "    tokens = doc.split()\n",
    "    #tokens = [word.lower() for word in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha() ]\n",
    "    #tokens = [word for word in tokens if not word in  stop_words]\n",
    "    #text = \" \".join(tokens)\n",
    "    return tokens#, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "893ba2a5-ee4a-4364-80d0-11660ab46b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_lines(tokens,length):\n",
    "    lines = []\n",
    "    for i in range(length,len(tokens)):\n",
    "        seq = tokens[i-length:i]\n",
    "        line  = \" \".join(seq)\n",
    "        lines.append(line)\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96c700de-1c0c-4567-94ef-ff1700c568a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full datasets\n",
    "dem_tokens = clean_data(DEM)\n",
    "gop_tokens = clean_data(GOP)\n",
    "\n",
    "dem_lines = return_lines(dem_tokens,10)\n",
    "gop_lines = return_lines(gop_tokens,10)\n",
    "\n",
    "#DEM datasets\n",
    "dem1_tokens = clean_data(DEM1)\n",
    "dem0_tokens = clean_data(DEM0)\n",
    "\n",
    "dem1_lines = return_lines(dem1_tokens,10)\n",
    "dem0_lines = return_lines(dem0_tokens,10)\n",
    "\n",
    "#GOP datasets\n",
    "gop1_tokens = clean_data(GOP1)\n",
    "gop0_tokens = clean_data(GOP0)\n",
    "\n",
    "gop1_lines = return_lines(gop1_tokens,10)\n",
    "gop0_lines = return_lines(gop0_tokens,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72187fa4-899b-4fea-92da-3c67b4151857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "    sequences = np.array(sequences)\n",
    "    X, y = sequences[:,:-1], sequences[:,-1]\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return X,y,vocab_size,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "324d8491-43c7-4cc0-a1c4-186c88633560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full datasets\n",
    "dem_X,dem_y,dem_vocab_size,dem_tokenizer = prepare_data(dem_lines)\n",
    "seq_dem = dem_X.shape[1] \n",
    "\n",
    "gop_X,gop_y,gop_vocab_size,gop_tokenizer = prepare_data(gop_lines)\n",
    "seq_gop = gop_X.shape[1] \n",
    "\n",
    "#DEM datasets\n",
    "dem1_X,dem1_y,dem1_vocab_size,dem1_tokenizer = prepare_data(dem1_lines)\n",
    "seq_dem1 = dem1_X.shape[1] \n",
    "\n",
    "dem0_X,dem0_y,dem0_vocab_size,dem0_tokenizer = prepare_data(dem0_lines)\n",
    "seq_dem0 = dem0_X.shape[1] \n",
    "\n",
    "#GOP datasets\n",
    "gop1_X,gop1_y,gop1_vocab_size,gop1_tokenizer = prepare_data(gop1_lines)\n",
    "seq_gop1 = gop1_X.shape[1] \n",
    "\n",
    "gop0_X,gop0_y,gop0_vocab_size,gop0_tokenizer = prepare_data(gop0_lines)\n",
    "seq_gop0 = gop0_X.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd826050-6edc-4bdb-b98b-4bb306a83e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn(X,y,epochs,vocab_size,seq):\n",
    "    model = keras.Sequential([keras.layers.Embedding(input_dim = vocab_size,output_dim=20,input_length=seq),\n",
    "                          keras.layers.Bidirectional(keras.layers.LSTM(100)),\n",
    "                          keras.layers.Dense(vocab_size,activation=\"softmax\")])\n",
    "    \n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",metrics=\"accuracy\",optimizer=\"adam\")\n",
    "    early_stop = keras.callbacks.EarlyStopping(patience=5)\n",
    "    \n",
    "    model.fit(X,y,epochs=epochs,callbacks=early_stop)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63091275-2d18-476a-9070-91fca24e8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_email(seed_text,num_word,model,seq):\n",
    "    for _ in range(num_word):\n",
    "        tokens = gop_tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        tokens = pad_sequences([tokens],maxlen=seq,padding=\"post\")\n",
    "    \n",
    "        predicted = np.argmax(model.predict(tokens))\n",
    "        outputword = \"\"\n",
    "    \n",
    "        for word,index in gop_tokenizer.word_index.items():\n",
    "            if predicted == index:\n",
    "                outputword = word\n",
    "                break\n",
    "            \n",
    "        seed_text += \" \" + outputword\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffedcdb1-e832-4d44-b674-b03f07240610",
   "metadata": {},
   "source": [
    "### Generate Positive DEM Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5880ddf6-c291-4999-adea-7d9598475add",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_rnn(dem1_X,dem1_y,5,dem1_vocab_size,seq_dem1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c28ab9-77e2-47ef-9ac5-8510b29bd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"republicans\"\n",
    "num_word = 50\n",
    "new_email(seed_text,num_word,model,seq_dem1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da9db2-fa1e-4d19-b4fe-c5404c773d68",
   "metadata": {},
   "source": [
    "### Generate Negative DEM Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0711c07f-c219-49c6-8b27-23ee12ef7907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 5.9217 - accuracy: 0.1281WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 137s 7ms/step - loss: 5.9217 - accuracy: 0.1281\n",
      "Epoch 2/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 5.0845 - accuracy: 0.2024WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 129s 7ms/step - loss: 5.0845 - accuracy: 0.2024\n",
      "Epoch 3/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 4.7201 - accuracy: 0.2349WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 126s 6ms/step - loss: 4.7201 - accuracy: 0.2349\n",
      "Epoch 4/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 4.4810 - accuracy: 0.2557WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 126s 6ms/step - loss: 4.4810 - accuracy: 0.2557\n",
      "Epoch 5/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 4.3042 - accuracy: 0.2707WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 128s 7ms/step - loss: 4.3042 - accuracy: 0.2707\n",
      "Epoch 6/15\n",
      "19500/19502 [============================>.] - ETA: 0s - loss: 4.1648 - accuracy: 0.2823WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 125s 6ms/step - loss: 4.1649 - accuracy: 0.2823\n",
      "Epoch 7/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 4.0557 - accuracy: 0.2910WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 129s 7ms/step - loss: 4.0557 - accuracy: 0.2910\n",
      "Epoch 8/15\n",
      "19499/19502 [============================>.] - ETA: 0s - loss: 3.9670 - accuracy: 0.2982WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 125s 6ms/step - loss: 3.9670 - accuracy: 0.2982\n",
      "Epoch 9/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 3.8894 - accuracy: 0.3054WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 129s 7ms/step - loss: 3.8894 - accuracy: 0.3054\n",
      "Epoch 10/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 3.8247 - accuracy: 0.3109WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 126s 6ms/step - loss: 3.8247 - accuracy: 0.3109\n",
      "Epoch 11/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 3.7703 - accuracy: 0.3161WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 130s 7ms/step - loss: 3.7703 - accuracy: 0.3161\n",
      "Epoch 12/15\n",
      "19495/19502 [============================>.] - ETA: 0s - loss: 3.7216 - accuracy: 0.3206WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 126s 6ms/step - loss: 3.7217 - accuracy: 0.3206\n",
      "Epoch 13/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 3.6796 - accuracy: 0.3241WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 126s 6ms/step - loss: 3.6796 - accuracy: 0.3241\n",
      "Epoch 14/15\n",
      "19502/19502 [==============================] - ETA: 0s - loss: 3.6407 - accuracy: 0.3280WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 130s 7ms/step - loss: 3.6407 - accuracy: 0.3280\n",
      "Epoch 15/15\n",
      "19496/19502 [============================>.] - ETA: 0s - loss: 3.6066 - accuracy: 0.3314WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "19502/19502 [==============================] - 127s 7ms/step - loss: 3.6066 - accuracy: 0.3314\n"
     ]
    }
   ],
   "source": [
    "model = model_rnn(dem0_X,dem0_y,15,dem0_vocab_size,seq_dem0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59506460-0077-4b42-b39b-4123b0bb8b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 734ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'republicans texasgopvote and and and and and and the did and i just county s is for so and here by lincoln single in the my s the agenda improve and a now all goal to america to the re of the did and the did it thepresident has to over'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = \"republicans\"\n",
    "num_word = 50\n",
    "new_email(seed_text,num_word,model,seq_dem0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083ad94-fcea-41a5-aad1-41e56921e902",
   "metadata": {},
   "source": [
    "### Generate Positive GOP Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82b70921-81c8-4641-b1fa-031f49c002d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40370/40374 [============================>.] - ETA: 0s - loss: 5.7801 - accuracy: 0.1618WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 396s 10ms/step - loss: 5.7801 - accuracy: 0.1618\n",
      "Epoch 2/15\n",
      "40374/40374 [==============================] - ETA: 0s - loss: 4.8537 - accuracy: 0.2554WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 381s 9ms/step - loss: 4.8537 - accuracy: 0.2554\n",
      "Epoch 3/15\n",
      "40373/40374 [============================>.] - ETA: 0s - loss: 4.5418 - accuracy: 0.2838WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 381s 9ms/step - loss: 4.5418 - accuracy: 0.2838\n",
      "Epoch 4/15\n",
      "40373/40374 [============================>.] - ETA: 0s - loss: 4.3561 - accuracy: 0.2989WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 385s 10ms/step - loss: 4.3561 - accuracy: 0.2989\n",
      "Epoch 5/15\n",
      "40370/40374 [============================>.] - ETA: 0s - loss: 4.2319 - accuracy: 0.3088WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 385s 10ms/step - loss: 4.2320 - accuracy: 0.3088\n",
      "Epoch 6/15\n",
      "40373/40374 [============================>.] - ETA: 0s - loss: 4.1449 - accuracy: 0.3162WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 387s 10ms/step - loss: 4.1449 - accuracy: 0.3162\n",
      "Epoch 7/15\n",
      "40373/40374 [============================>.] - ETA: 0s - loss: 4.0666 - accuracy: 0.3223WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 383s 9ms/step - loss: 4.0667 - accuracy: 0.3223\n",
      "Epoch 8/15\n",
      "40371/40374 [============================>.] - ETA: 0s - loss: 4.0024 - accuracy: 0.3275WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 385s 10ms/step - loss: 4.0023 - accuracy: 0.3275\n",
      "Epoch 9/15\n",
      "40373/40374 [============================>.] - ETA: 0s - loss: 3.9452 - accuracy: 0.3321WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 384s 10ms/step - loss: 3.9452 - accuracy: 0.3321\n",
      "Epoch 10/15\n",
      "40374/40374 [==============================] - ETA: 0s - loss: 3.8961 - accuracy: 0.3366WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 383s 9ms/step - loss: 3.8961 - accuracy: 0.3366\n",
      "Epoch 11/15\n",
      "40372/40374 [============================>.] - ETA: 0s - loss: 3.8497 - accuracy: 0.3405WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 384s 10ms/step - loss: 3.8497 - accuracy: 0.3405\n",
      "Epoch 12/15\n",
      "40370/40374 [============================>.] - ETA: 0s - loss: 3.8061 - accuracy: 0.3442WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 383s 9ms/step - loss: 3.8061 - accuracy: 0.3442\n",
      "Epoch 13/15\n",
      "40372/40374 [============================>.] - ETA: 0s - loss: 3.7665 - accuracy: 0.3479WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 382s 9ms/step - loss: 3.7665 - accuracy: 0.3479\n",
      "Epoch 14/15\n",
      "40373/40374 [============================>.] - ETA: 0s - loss: 3.7290 - accuracy: 0.3508WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 386s 10ms/step - loss: 3.7291 - accuracy: 0.3508\n",
      "Epoch 15/15\n",
      "40370/40374 [============================>.] - ETA: 0s - loss: 3.6941 - accuracy: 0.3538WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "40374/40374 [==============================] - 380s 9ms/step - loss: 3.6941 - accuracy: 0.3538\n"
     ]
    }
   ],
   "source": [
    "model = model_rnn(gop1_X,gop1_y,15,gop1_vocab_size,seq_gop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22bf4025-1f01-49dc-af26-b372008ea1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'democrats opioid opioid opioid opioid opioid opioid regional refusing beating in the re of the nancy united and the f s officials same of side and the side of the f s side and dependent i s right that what plan for your from to computer our keep and leading a'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = \"democrats\"\n",
    "num_word = 50\n",
    "new_email(seed_text,num_word,model,seq_gop1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3053ae1-809c-4e61-ba0b-a1b84d863c1f",
   "metadata": {},
   "source": [
    "### Generate Negative GOP Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4e498f9-313e-4212-a858-9a825fc74bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6118/6118 [==============================] - ETA: 0s - loss: 6.5506 - accuracy: 0.0826WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 46s 7ms/step - loss: 6.5506 - accuracy: 0.0826\n",
      "Epoch 2/25\n",
      "6110/6118 [============================>.] - ETA: 0s - loss: 5.5266 - accuracy: 0.1650WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 5.5262 - accuracy: 0.1651\n",
      "Epoch 3/25\n",
      "6111/6118 [============================>.] - ETA: 0s - loss: 4.9582 - accuracy: 0.2116WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 4.9583 - accuracy: 0.2116\n",
      "Epoch 4/25\n",
      "6110/6118 [============================>.] - ETA: 0s - loss: 4.5283 - accuracy: 0.2457WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 36s 6ms/step - loss: 4.5284 - accuracy: 0.2457\n",
      "Epoch 5/25\n",
      "6118/6118 [==============================] - ETA: 0s - loss: 4.1672 - accuracy: 0.2746WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 36s 6ms/step - loss: 4.1672 - accuracy: 0.2746\n",
      "Epoch 6/25\n",
      "6114/6118 [============================>.] - ETA: 0s - loss: 3.8544 - accuracy: 0.3039WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 3.8544 - accuracy: 0.3039\n",
      "Epoch 7/25\n",
      "6117/6118 [============================>.] - ETA: 0s - loss: 3.5822 - accuracy: 0.3321WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 36s 6ms/step - loss: 3.5822 - accuracy: 0.3321\n",
      "Epoch 8/25\n",
      "6115/6118 [============================>.] - ETA: 0s - loss: 3.3459 - accuracy: 0.3609WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 3.3461 - accuracy: 0.3609\n",
      "Epoch 9/25\n",
      "6111/6118 [============================>.] - ETA: 0s - loss: 3.1388 - accuracy: 0.3884WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 3.1389 - accuracy: 0.3884\n",
      "Epoch 10/25\n",
      "6112/6118 [============================>.] - ETA: 0s - loss: 2.9590 - accuracy: 0.4138WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 2.9592 - accuracy: 0.4138\n",
      "Epoch 11/25\n",
      "6116/6118 [============================>.] - ETA: 0s - loss: 2.8010 - accuracy: 0.4374WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 2.8010 - accuracy: 0.4374\n",
      "Epoch 12/25\n",
      "6111/6118 [============================>.] - ETA: 0s - loss: 2.6629 - accuracy: 0.4572WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 36s 6ms/step - loss: 2.6630 - accuracy: 0.4572\n",
      "Epoch 13/25\n",
      "6118/6118 [==============================] - ETA: 0s - loss: 2.5398 - accuracy: 0.4766WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 2.5398 - accuracy: 0.4766\n",
      "Epoch 14/25\n",
      "6115/6118 [============================>.] - ETA: 0s - loss: 2.4276 - accuracy: 0.4946WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 36s 6ms/step - loss: 2.4276 - accuracy: 0.4945\n",
      "Epoch 15/25\n",
      "6115/6118 [============================>.] - ETA: 0s - loss: 2.3273 - accuracy: 0.5111WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 2.3274 - accuracy: 0.5111\n",
      "Epoch 16/25\n",
      "6118/6118 [==============================] - ETA: 0s - loss: 2.2348 - accuracy: 0.5269WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 2.2348 - accuracy: 0.5269\n",
      "Epoch 17/25\n",
      "6113/6118 [============================>.] - ETA: 0s - loss: 2.1562 - accuracy: 0.5402WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 2.1563 - accuracy: 0.5402\n",
      "Epoch 18/25\n",
      "6115/6118 [============================>.] - ETA: 0s - loss: 2.0812 - accuracy: 0.5537WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 36s 6ms/step - loss: 2.0812 - accuracy: 0.5537\n",
      "Epoch 19/25\n",
      "6113/6118 [============================>.] - ETA: 0s - loss: 2.0122 - accuracy: 0.5664WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 2.0122 - accuracy: 0.5664\n",
      "Epoch 20/25\n",
      "6113/6118 [============================>.] - ETA: 0s - loss: 1.9487 - accuracy: 0.5765WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 36s 6ms/step - loss: 1.9487 - accuracy: 0.5765\n",
      "Epoch 21/25\n",
      "6116/6118 [============================>.] - ETA: 0s - loss: 1.8926 - accuracy: 0.5870WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 1.8927 - accuracy: 0.5870\n",
      "Epoch 22/25\n",
      "6112/6118 [============================>.] - ETA: 0s - loss: 1.8391 - accuracy: 0.5968WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 1.8392 - accuracy: 0.5968\n",
      "Epoch 23/25\n",
      "6116/6118 [============================>.] - ETA: 0s - loss: 1.7911 - accuracy: 0.6055WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 1.7912 - accuracy: 0.6055\n",
      "Epoch 24/25\n",
      "6118/6118 [==============================] - ETA: 0s - loss: 1.7430 - accuracy: 0.6129WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 1.7430 - accuracy: 0.6129\n",
      "Epoch 25/25\n",
      "6117/6118 [============================>.] - ETA: 0s - loss: 1.7007 - accuracy: 0.6225WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "6118/6118 [==============================] - 37s 6ms/step - loss: 1.7007 - accuracy: 0.6225\n"
     ]
    }
   ],
   "source": [
    "model = model_rnn(gop0_X,gop0_y,25,gop0_vocab_size,seq_gop0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70768d19-191b-4d47-a768-b284f221ec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 749ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'democrats by by joined allowing in voted usmca management the take america the topic tricks did out great now within america father to the not and new learn grateful help ask today from advisor borders to the not of the so not m addiction illegal ll group in the please border'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = \"democrats\"\n",
    "num_word = 50\n",
    "new_email(seed_text,num_word,model,seq_gop0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b089ef-4437-405d-8f24-96f59973095a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
