{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "from tensorflow import keras\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "Sm1yTXzS77kl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read in the data\n",
        "import pandas as pd\n",
        "\n",
        "df1=pd.read_csv(\"https://raw.githubusercontent.com/statzenthusiast921/political-emails-analysis/main/main/data/clean_emails_df1.csv\")\n",
        "df2=pd.read_csv(\"https://raw.githubusercontent.com/statzenthusiast921/political-emails-analysis/main/main/data/clean_emails_df2.csv\")\n",
        "df3=pd.read_csv(\"https://raw.githubusercontent.com/statzenthusiast921/political-emails-analysis/main/main/data/clean_emails_df3.csv\")\n",
        "df4=pd.read_csv(\"https://raw.githubusercontent.com/statzenthusiast921/political-emails-analysis/main/main/data/clean_emails_df4.csv\")\n",
        "\n",
        "print(df1.shape)\n",
        "print(df2.shape)\n",
        "print(df3.shape)\n",
        "print(df4.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aKb-Rc6ToJX",
        "outputId": "0c9e1d25-83d4-484e-fbcb-b83242d63945"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19000, 20)\n",
            "(19000, 20)\n",
            "(19000, 20)\n",
            "(17148, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stack 4 dataframes together\n",
        "df = pd.concat([df1, df2, df3, df4], ignore_index=True, axis=0)\n",
        "#Delete first row and column\n",
        "df = df[1:]\n",
        "df = df.iloc[: , 1:]\n",
        "\n",
        "#Drop NAs from cleaned_body and body\n",
        "df = df[df['cleaned_body'].notna()]\n",
        "#Preview dataframe\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "PcuUo3gtTul1",
        "outputId": "1dfceee7-4daa-4589-afa7-f54acd757c22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             subject          date  \\\n",
              "1            TAKE ACTION for Freedom: #CloseTheCamps  July 3, 2019   \n",
              "2                            trauma-informed schools  July 3, 2019   \n",
              "3                                            JuaÃÅrez  July 3, 2019   \n",
              "4                      Andy's new veterans jobs plan  July 4, 2019   \n",
              "5  say NO to Trump's military parade [signature n...  July 4, 2019   \n",
              "\n",
              "                                                body       party  \\\n",
              "1  Dear friend, We have all seen the images and r...         NaN   \n",
              "2  Team,Access to education is fundamental to a c...  Democratic   \n",
              "3   Beto for America John, The Trump administrati...  Democratic   \n",
              "4  John,Tomorrow is the Fourth of July, a day for...  Democratic   \n",
              "5  Tomorrow is the Fourth of July, and Donald Tru...  Democratic   \n",
              "\n",
              "         country  locality                          office      time AM_PM  \\\n",
              "1  United States       NaN                             NaN  11:31 PM    PM   \n",
              "2  United States      Ohio  President of the United States  11:32 PM    PM   \n",
              "3  United States     Texas  President of the United States  11:32 PM    PM   \n",
              "4  United States  Kentucky                  State Governor  12:15 AM    AM   \n",
              "5  United States       NaN  President of the United States  12:19 AM    AM   \n",
              "\n",
              "   Hour  Hour_Mil month  day  year  month_num  \\\n",
              "1    11        23  July    3  2019          7   \n",
              "2    11        23  July    3  2019          7   \n",
              "3    11        23  July    3  2019          7   \n",
              "4    12         0  July    4  2019          7   \n",
              "5    12         0  July    4  2019          7   \n",
              "\n",
              "                                        cleaned_body  \\\n",
              "1  dear friend seen images read stories migrants ...   \n",
              "2  team access education fundamental child succes...   \n",
              "3  beto america john trump administration created...   \n",
              "4  john tomorrow fourth july day us come together...   \n",
              "5  tomorrow fourth july donald trump using day th...   \n",
              "\n",
              "                                           sentiment  compound  comp_score  \n",
              "1  {'neg': 0.207, 'neu': 0.674, 'pos': 0.12, 'com...   -0.9807           0  \n",
              "2  {'neg': 0.143, 'neu': 0.658, 'pos': 0.199, 'co...    0.7269           1  \n",
              "3  {'neg': 0.069, 'neu': 0.684, 'pos': 0.247, 'co...    0.9578           1  \n",
              "4  {'neg': 0.023, 'neu': 0.636, 'pos': 0.341, 'co...    0.9867           1  \n",
              "5  {'neg': 0.078, 'neu': 0.684, 'pos': 0.238, 'co...    0.8316           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82fc0c2f-b3de-49c3-88e5-ee778fd04136\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>body</th>\n",
              "      <th>party</th>\n",
              "      <th>country</th>\n",
              "      <th>locality</th>\n",
              "      <th>office</th>\n",
              "      <th>time</th>\n",
              "      <th>AM_PM</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Hour_Mil</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>month_num</th>\n",
              "      <th>cleaned_body</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>compound</th>\n",
              "      <th>comp_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TAKE ACTION for Freedom: #CloseTheCamps</td>\n",
              "      <td>July 3, 2019</td>\n",
              "      <td>Dear friend, We have all seen the images and r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11:31 PM</td>\n",
              "      <td>PM</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>July</td>\n",
              "      <td>3</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>dear friend seen images read stories migrants ...</td>\n",
              "      <td>{'neg': 0.207, 'neu': 0.674, 'pos': 0.12, 'com...</td>\n",
              "      <td>-0.9807</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>trauma-informed schools</td>\n",
              "      <td>July 3, 2019</td>\n",
              "      <td>Team,Access to education is fundamental to a c...</td>\n",
              "      <td>Democratic</td>\n",
              "      <td>United States</td>\n",
              "      <td>Ohio</td>\n",
              "      <td>President of the United States</td>\n",
              "      <td>11:32 PM</td>\n",
              "      <td>PM</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>July</td>\n",
              "      <td>3</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>team access education fundamental child succes...</td>\n",
              "      <td>{'neg': 0.143, 'neu': 0.658, 'pos': 0.199, 'co...</td>\n",
              "      <td>0.7269</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JuaÃÅrez</td>\n",
              "      <td>July 3, 2019</td>\n",
              "      <td>Beto for America John, The Trump administrati...</td>\n",
              "      <td>Democratic</td>\n",
              "      <td>United States</td>\n",
              "      <td>Texas</td>\n",
              "      <td>President of the United States</td>\n",
              "      <td>11:32 PM</td>\n",
              "      <td>PM</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>July</td>\n",
              "      <td>3</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>beto america john trump administration created...</td>\n",
              "      <td>{'neg': 0.069, 'neu': 0.684, 'pos': 0.247, 'co...</td>\n",
              "      <td>0.9578</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Andy's new veterans jobs plan</td>\n",
              "      <td>July 4, 2019</td>\n",
              "      <td>John,Tomorrow is the Fourth of July, a day for...</td>\n",
              "      <td>Democratic</td>\n",
              "      <td>United States</td>\n",
              "      <td>Kentucky</td>\n",
              "      <td>State Governor</td>\n",
              "      <td>12:15 AM</td>\n",
              "      <td>AM</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>July</td>\n",
              "      <td>4</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>john tomorrow fourth july day us come together...</td>\n",
              "      <td>{'neg': 0.023, 'neu': 0.636, 'pos': 0.341, 'co...</td>\n",
              "      <td>0.9867</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>say NO to Trump's military parade [signature n...</td>\n",
              "      <td>July 4, 2019</td>\n",
              "      <td>Tomorrow is the Fourth of July, and Donald Tru...</td>\n",
              "      <td>Democratic</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>President of the United States</td>\n",
              "      <td>12:19 AM</td>\n",
              "      <td>AM</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>July</td>\n",
              "      <td>4</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>tomorrow fourth july donald trump using day th...</td>\n",
              "      <td>{'neg': 0.078, 'neu': 0.684, 'pos': 0.238, 'co...</td>\n",
              "      <td>0.8316</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82fc0c2f-b3de-49c3-88e5-ee778fd04136')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82fc0c2f-b3de-49c3-88e5-ee778fd04136 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82fc0c2f-b3de-49c3-88e5-ee778fd04136');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['year']>1970]\n",
        "df['locality'] = np.where(df['locality']==\"MIchigan\",\"Michigan\",df['locality'])\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShbgN6xGT5tJ",
        "outputId": "254532b4-e10b-447b-c5dc-fcf526b997dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73694, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend([\"uh\",\"oh\",\"okay\",\"im\",\"dont\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "musZ6d0c79_r",
        "outputId": "b1b6ae94-1bf4-436e-c951-549ddb618ba4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['body'] = df['body'].astype('string')\n"
      ],
      "metadata": {
        "id": "nURNmGwY7rWl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_brackets_contents(text):\n",
        "    pattern = r\"\\[.*?\\]\"\n",
        "    return re.sub(pattern, \" \", text)\n",
        "\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # define the pattern to keep\n",
        "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
        "    return re.sub(pat, ' ', text)"
      ],
      "metadata": {
        "id": "ifPJzrl58RZT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df['body'] = df['body'].replace('\\n','',regex=True)\n",
        "df['body'] = df['body'].replace('\\r','',regex=True)\n",
        "df.loc[:,'body'] = df['body'].apply(func = remove_brackets_contents)\n",
        "df.loc[:,'body'] = df['body'].apply(func = remove_special_characters)\n",
        "\n",
        "\n",
        "df['body'] = df['body'].replace('   ',' ',regex=True)\n",
        "df['body'] = df['body'].replace('    ',' ',regex=True)\n",
        "df['body'] = df['body'].replace('     ',' ',regex=True)\n",
        "\n",
        "df['body'] = df['body'].replace(']',' ',regex=True)\n",
        "df['body'] = df['body'].replace('\\xa0',' ',regex=True)\n",
        "df['body'] = df['body'].replace('almostdaily','almost daily',regex=True)\n",
        "\n",
        "\n",
        "#Remove all the text that follows these sentences\n",
        "df['body'] = df['body'].str.replace(\"(If you need to remove yourself from our email).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Email is the most important way).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(This email was sent to).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Thank you for speaking).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(All Rights Reserved).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(mailto:).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Thank you for choosing to fight).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Paid for by).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(We look forward to hearing from you).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(PAID FOR BY).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Thanks for your).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(All rights reserved).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(unsubscribe).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Sincerely).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Facebook).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Twitter).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Please, sign your name).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(CONTRIBUTE).*\",\"\")\n",
        "df['body'] = df['body'].str.replace(\"(Contribute).*\",\"\")\n"
      ],
      "metadata": {
        "id": "woJnKx7i7rT1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "!pip install contractions\n",
        "import contractions\n",
        "\n",
        "def punct(text):\n",
        "    token=RegexpTokenizer(r'\\w+')#regex\n",
        "    text = token.tokenize(text)\n",
        "    text= \" \".join(text)\n",
        "    return text \n",
        "\n",
        "def remove_special_characters(text):\n",
        "    # define the pattern to keep\n",
        "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
        "    return re.sub(pat, '', text)\n",
        "\n",
        "def remove_digits(text):\n",
        "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
        "    return re.sub(pattern, '', text)\n",
        "\n",
        "def lemmatize(text):\n",
        "    lemmed = contractions.fix(str(text))\n",
        "    return lemmed\n",
        "\n",
        "\n",
        "\n",
        "def remove_weird_words_that_showed_up_in_analysis_(str):\n",
        "    #select english stopwords\n",
        "    #cachedStopWords = set(stopwords.words(\"english\"))\n",
        "    #add custom words\n",
        "    cachedStopWords = set(('height','width','style','saved','payment','information','https',\n",
        "                            'fmailchi','mp','chip','tr','td','style','font','size','px','view'\n",
        "                            'email','browser','zwnj','metered','paywall','articles','vertical',\n",
        "                            'align','top','item','img','src','rss','mc','actblue','com','donate',\n",
        "                            'donation', 'padding','bottom', 'members','pre','unsubscribe','rsquo',\n",
        "                            'headline','lead story','body lead','view email','story body','copy paste',\n",
        "                            'address window','web update','web page','receiving email','page go',\n",
        "                            'go link','paste link','copy fact','receiving newsletter','anymore click',\n",
        "                            'newsletter shown','newsletter clicking','interested anymore','emails view',\n",
        "                            'html emails','software display','display html','please click','web updates',\n",
        "                            'email','emails','interest','interested','newsletter'\n",
        "                           ))\n",
        "    #remove stop words\n",
        "    new_str = ' '.join([word for word in str.split() if word not in cachedStopWords]) \n",
        "    return new_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s2oLvgx7rRO",
        "outputId": "64f7f913-13b8-4766-896c-83a773cb4ebc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 287 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110 kB 57.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply standardizing functions to body of email column\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "#0.) Convert everything to string\n",
        "df['cleaned_body'] = df['body'].astype(str)\n",
        "#1.) Lowercase\n",
        "df.loc[:,'cleaned_body'] = df['cleaned_body'].str.lower()\n",
        "#2.) Remove punctuation\n",
        "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = punct)\n",
        "#3.) Remove non alpha-numeric characters\n",
        "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = remove_special_characters)\n",
        "#4.) Remove digits\n",
        "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = remove_digits)\n",
        "#5.) Lemmatize words\n",
        "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = lemmatize)\n",
        "#6. Remove stop words\n",
        "#df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "#7. Remove weird words that showed up in the analysis\n",
        "df.loc[:,'cleaned_body'] = df['cleaned_body'].apply(func = remove_weird_words_that_showed_up_in_analysis_)\n",
        "\n",
        "#Present results\n",
        "df['cleaned_body'].head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwcDOK_77rOo",
        "outputId": "ffab648b-d975-4e73-ef45-888e29bfd036"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    dear friend we have all seen the images and re...\n",
              "2    team access to education is fundamental to a c...\n",
              "3    beto for america john the trump administration...\n",
              "4    john tomorrow is the fourth of july a day for ...\n",
              "5    tomorrow is the fourth of july and donald trum...\n",
              "Name: cleaned_body, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dom = df[df['country']==\"United States\"]\n",
        "\n",
        "DEM_df = df_dom[df_dom['party']==\"Democratic\"].reset_index(drop=True)\n",
        "GOP_df = df_dom[df_dom['party']==\"Republican\"].reset_index(drop=True)\n",
        "\n",
        "print(DEM_df.shape)\n",
        "print(GOP_df.shape)"
      ],
      "metadata": {
        "id": "7VuNaYRS9D8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ab2f34-2925-42a0-b8b8-62fb0551e7f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27737, 19)\n",
            "(6538, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEM = DEM_df.cleaned_body\n",
        "GOP = GOP_df.cleaned_body"
      ],
      "metadata": {
        "id": "tbCaqFwK9GkD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(doc):\n",
        "    doc = \"\".join(doc)\n",
        "    doc = re.sub(r'[^\\w\\s]', '', doc)\n",
        "    tokens = doc.split()\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    tokens = [word for word in tokens if word.isalpha() ]\n",
        "    #tokens = [word for word in tokens if not word in  stop_words]\n",
        "    text = \" \".join(tokens)\n",
        "    return tokens#,text"
      ],
      "metadata": {
        "id": "tY45hhE99R3q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_lines(tokens,length):\n",
        "    lines = []\n",
        "    for i in range(length,len(tokens)):\n",
        "        seq = tokens[i-length:i]\n",
        "        line  = \" \".join(seq)\n",
        "        lines.append(line)\n",
        "        \n",
        "    return lines"
      ],
      "metadata": {
        "id": "3bVJIHUj9gWB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dem_tokens = clean_data(DEM)\n",
        "gop_tokens = clean_data(GOP)\n",
        "\n",
        "dem_lines = return_lines(dem_tokens,10)\n",
        "gop_lines = return_lines(gop_tokens,10)"
      ],
      "metadata": {
        "id": "Zg-QFyBLV0Qu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(data)\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "    sequences = np.array(sequences)\n",
        "    X, y = sequences[:,:-1], sequences[:,-1]\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    return X,y,vocab_size,tokenizer"
      ],
      "metadata": {
        "id": "wfCMIMFU9nNW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dem_X,dem_y,dem_vocab_size,dem_tokenizer = prepare_data(dem_lines)\n",
        "seq_dem = dem_X.shape[1] \n",
        "\n",
        "gop_X,gop_y,gop_vocab_size,gop_tokenizer = prepare_data(gop_lines)\n",
        "seq_gop = gop_X.shape[1] "
      ],
      "metadata": {
        "id": "S8LaCc829p8R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_rnn(X,y,epochs,vocab_size,seq):\n",
        "    model = keras.Sequential([keras.layers.Embedding(input_dim = vocab_size,output_dim=20,input_length=seq),\n",
        "                          keras.layers.Bidirectional(keras.layers.LSTM(100)),\n",
        "                          keras.layers.Dense(vocab_size,activation=\"softmax\")])\n",
        "    \n",
        "    \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",metrics=\"accuracy\",optimizer=\"adam\")\n",
        "    early_stop = keras.callbacks.EarlyStopping(patience=5)\n",
        "    \n",
        "    model.fit(X,y,epochs=epochs,callbacks=early_stop)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "T_dY04yT9vnf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_rnn(gop_X,gop_y,20,gop_vocab_size,seq_gop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfOZDbQZ9zqe",
        "outputId": "69209f73-4deb-4e7e-df03-f23c35576898"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "46492/46492 [==============================] - ETA: 0s - loss: 5.7268 - accuracy: 0.1689"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 548s 12ms/step - loss: 5.7268 - accuracy: 0.1689\n",
            "Epoch 2/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 4.8489 - accuracy: 0.2581"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 531s 11ms/step - loss: 4.8489 - accuracy: 0.2581\n",
            "Epoch 3/20\n",
            "46488/46492 [============================>.] - ETA: 0s - loss: 4.5591 - accuracy: 0.2842"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 542s 12ms/step - loss: 4.5591 - accuracy: 0.2842\n",
            "Epoch 4/20\n",
            "46491/46492 [============================>.] - ETA: 0s - loss: 4.3932 - accuracy: 0.2979"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 538s 12ms/step - loss: 4.3932 - accuracy: 0.2979\n",
            "Epoch 5/20\n",
            "46491/46492 [============================>.] - ETA: 0s - loss: 4.2774 - accuracy: 0.3069"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 535s 12ms/step - loss: 4.2774 - accuracy: 0.3069\n",
            "Epoch 6/20\n",
            "46492/46492 [==============================] - ETA: 0s - loss: 4.1919 - accuracy: 0.3137"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 535s 11ms/step - loss: 4.1919 - accuracy: 0.3137\n",
            "Epoch 7/20\n",
            "46488/46492 [============================>.] - ETA: 0s - loss: 4.1177 - accuracy: 0.3196"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 538s 12ms/step - loss: 4.1177 - accuracy: 0.3196\n",
            "Epoch 8/20\n",
            "46492/46492 [==============================] - ETA: 0s - loss: 4.0570 - accuracy: 0.3248"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 537s 12ms/step - loss: 4.0570 - accuracy: 0.3248\n",
            "Epoch 9/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 3.9998 - accuracy: 0.3291"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 536s 12ms/step - loss: 3.9998 - accuracy: 0.3291\n",
            "Epoch 10/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 3.9446 - accuracy: 0.3332"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 535s 12ms/step - loss: 3.9446 - accuracy: 0.3332\n",
            "Epoch 11/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 3.8977 - accuracy: 0.3368"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 536s 12ms/step - loss: 3.8977 - accuracy: 0.3368\n",
            "Epoch 12/20\n",
            "46491/46492 [============================>.] - ETA: 0s - loss: 3.8587 - accuracy: 0.3397"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 537s 12ms/step - loss: 3.8587 - accuracy: 0.3397\n",
            "Epoch 13/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 3.8283 - accuracy: 0.3420"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 533s 11ms/step - loss: 3.8283 - accuracy: 0.3420\n",
            "Epoch 14/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 3.7988 - accuracy: 0.3449"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 546s 12ms/step - loss: 3.7988 - accuracy: 0.3449\n",
            "Epoch 15/20\n",
            "46488/46492 [============================>.] - ETA: 0s - loss: 3.7697 - accuracy: 0.3473"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 536s 12ms/step - loss: 3.7697 - accuracy: 0.3473\n",
            "Epoch 16/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 3.7410 - accuracy: 0.3499"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46492/46492 [==============================] - 534s 11ms/step - loss: 3.7410 - accuracy: 0.3499\n",
            "Epoch 17/20\n",
            "46492/46492 [==============================] - ETA: 0s - loss: 3.7155 - accuracy: 0.3518"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46492/46492 [==============================] - 538s 12ms/step - loss: 3.7155 - accuracy: 0.3518\n",
            "Epoch 18/20\n",
            "46489/46492 [============================>.] - ETA: 0s - loss: 3.6910 - accuracy: 0.3539"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46492/46492 [==============================] - 533s 11ms/step - loss: 3.6910 - accuracy: 0.3539\n",
            "Epoch 19/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 3.6673 - accuracy: 0.3564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46492/46492 [==============================] - 533s 11ms/step - loss: 3.6673 - accuracy: 0.3564\n",
            "Epoch 20/20\n",
            "46490/46492 [============================>.] - ETA: 0s - loss: 3.6404 - accuracy: 0.3586"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r46492/46492 [==============================] - 533s 11ms/step - loss: 3.6403 - accuracy: 0.3586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"democrats\"\n",
        "num_word = 50\n",
        "def new_email(seed_text,num_word,model,seq):\n",
        "    for _ in range(num_word):\n",
        "        tokens = gop_tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        tokens = pad_sequences([tokens],maxlen=seq,padding=\"post\")\n",
        "    \n",
        "        predicted = np.argmax(model.predict(tokens))\n",
        "        outputword = \"\"\n",
        "    \n",
        "        for word,index in gop_tokenizer.word_index.items():\n",
        "            if predicted == index:\n",
        "                outputword = word\n",
        "                break\n",
        "            \n",
        "        seed_text += \" \" + outputword\n",
        "    return seed_text\n",
        "\n",
        "new_email(seed_text,num_word,model,seq_gop)"
      ],
      "metadata": {
        "id": "PW7_y59x92DG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "outputId": "c1024d89-d516-4d02-ccc8-053d38843f7a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'democrats killing killing killing killing raises schools opposing abortions and impose they have a sick of crime and the rest of the democratic party has been recognized by the right direction to the united states mexico canada agreement usmca is a total of the second amendment bans socialism and they want'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0U4FZEqSEH9d"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}